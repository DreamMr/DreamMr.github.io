<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>wwb个人主页</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">wwb个人主页</h2>
        </a>
        <ul>
          <li><a href="/">About</a></li>
          <li><a href="/portfolio/">Portfolio</a></li>
        </ul>
    </div>
  </nav>

    <main>
      <div class="post">
  <h2 class="post-title">SimCLR阅读</h2>
  <div class="post-line"></div>

  <h1 id="背景">背景</h1>

<p>以往自监督学习中方法的局限性。</p>

<pre><code class="language-mermaid">graph LR
A[自监督学习方法]--&gt;B[生成式]
A[自监督学习方法]--&gt;C[判别式]
B[生成式]--&gt;D[像素级别的生成计算复杂度较高]
C[判别式]--&gt;E[往往特征表示受限于启发式的pretext task]
</code></pre>

<h1 id="论文的贡献点">论文的贡献点</h1>

<ol>
  <li>针对不同类型的数据增强组合能够有效的改善特征的表达。此外对比学习能够比监督学习更好的从数据增强中有明显改善。</li>
  <li>引入一种可学习的非线性变换，这种变换在特征表示和对比学习的loss对学到的特征表示有本质的改善。（函数g）</li>
  <li>对比交叉熵loss的表示学习受益于标准化的embedding和合适的温控参数</li>
  <li>对比学习受益于大的batch size和长时间的训练相对于监督学习而言。与监督学习一样，对比学习也受益于更深更宽的网络。</li>
</ol>

<h1 id="方法">方法</h1>

<p><img src="../assets/img/SimCLR/image-20210619202720863.png" alt="image-20210619202720863" /></p>

<p>$\intercal$ 表示某种类型的数据增强操作（例如裁剪、颜色变化等）</p>

<p>大致思路：首先将x经过两种不同类型的数据增强操作后分别得到$\tilde{x_i}$ 和$\tilde{x_j}$ ,然后经过函数f,用于提取向量表示，这个f可以是任意的网络，例如：$h_i=f(\tilde{x_i})=ResNet(\tilde{x_i})$ .接着是一个projection head $g()$是一个映射网络，用于将学到的特征表示映射到对比loss的空间中。这里的g是一个隐藏层：$z_i=g(h_i)W^2\sigma(W^1h_i)$ ,其中$\sigma$ 是ReLU激活函数。</p>

<p>constrative loss:
\(l_{i,j}=-log\frac{exp(sim(z_i,z_j)/\tau)}{\sum_{k=1}^{2N}1_{[k\nei]}exp(sim(z_i,z_k)/\tau)}\)
即将$z_i$和$z_j$ 通过计算两者的距离，然后用<strong>NT-Xent(the normalized temperature-scaled cross entropy loss)</strong>来计算两者是否来自同一张图片</p>

<p>伪代码：</p>

<p><img src="../assets/img/SimCLR/image-20210619205020941.png" alt="image-20210619205020941" /></p>

<h1 id="实验">实验</h1>

<h2 id="数据增强对于contrastive-表示学习">数据增强对于Contrastive 表示学习</h2>

<ul>
  <li>
    <p>不同类型的数据增强</p>

    <p><img src="../assets/img/SimCLR/image-20210619210737356.png" alt="image-20210619210737356" /></p>

    <p>两种不同类型的数据增强在线性评估中能够带来更好的效果。其中效果最好的是进行颜色变化和随机裁剪的一组。</p>

    <p><img src="../assets/img/SimCLR/image-20210619210929425.png" alt="image-20210619210929425" /></p>

    <p>从上图的(a)中可以发现，他们像素的分布几乎都是一样的，所以如果单独只用随机的裁剪，导致那么这些从同一张图片中进行随机裁剪出来的patch他们在颜色上的分布几乎一样，所以网络会很容易从中学到，那么就不会学到什么有用的东西。而在加入颜色变化后，颜色的分布变得复杂了，能够学到更复杂的表示。</p>
  </li>
  <li>
    <p>Constrative learning相对于监督学习来说更适合数据增强</p>

    <p><img src="../assets/img/SimCLR/image-20210619212144015.png" alt="image-20210619212144015" /></p>
  </li>
</ul>

<h2 id="网络结构实验">网络结构实验</h2>

<ul>
  <li>
    <p>无监督的Contrastive learning能够从更大的模型中学到东西</p>

    <p><img src="../assets/img/SimCLR/image-20210619212439227.png" alt="image-20210619212439227" /></p>
  </li>
  <li>
    <p>非线性映射在representation之后能够提高representation的质量</p>

    <p><img src="../assets/img/SimCLR/image-20210619212800308.png" alt="image-20210619212800308" /></p>

    <p>作者发现使用非线性映射能够获得更好的表达效果。另外，从最后一个比较中可以发现，使用了非线性映射后放在representation的后面效果较好（没有使用相当于是放在representation的后面）</p>

    <p><img src="../assets/img/SimCLR/image-20210619212812773.png" alt="image-20210619212812773" /></p>

    <p>作者想通过这个表格说明中间学到的representation h相比于g(h)能够包含更多有用的信息。</p>
  </li>
  <li>
    <p>标准化的交叉熵损失函数和合适的温控参数能够有更好的效果</p>

    <p><img src="../assets/img/SimCLR/image-20210619215009497.png" alt="image-20210619215009497" /></p>

    <p>NT-Xent在进行求导的时候能够更好的考虑负样本</p>

    <p><img src="../assets/img/SimCLR/image-20210619214821597.png" alt="image-20210619214821597" /></p>

    <p><img src="../assets/img/SimCLR/image-20210619214831841.png" alt="image-20210619214831841" /></p>
  </li>
  <li>
    <p>Contrastive learning能够从更大的batch size和更长的训练中进行训练</p>

    <p><img src="../assets/img/SimCLR/image-20210619215535968.png" alt="image-20210619215535968" /></p>
  </li>
</ul>

<h2 id="与sota对比">与SOTA对比</h2>

<ul>
  <li>
    <p>线性评估</p>

    <p><img src="../assets/img/SimCLR/image-20210619215854973.png" alt="image-20210619215854973" /></p>
  </li>
  <li>
    <p>半监督学习对比</p>

    <p><img src="../assets/img/SimCLR/image-20210619215907776.png" alt="image-20210619215907776" /></p>
  </li>
  <li>
    <p>迁移学习对比</p>

    <p><img src="../assets/img/SimCLR/image-20210619215943542.png" alt="image-20210619215943542" /></p>
  </li>
</ul>



</div>

<div class="pagination">
  
    <a href="/2021-09-12/Docker%E6%90%AD%E5%BB%BAdeeplearning%E7%8E%AF%E5%A2%83" class="left next">Prev</a>
  
  
    <a href="/2021-06-04/%E6%A0%87%E5%87%86%E5%8C%96%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93" class="right next">Next</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2023-02-03 00:12:03 +0800">2023</time> 王文斌. <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme by kssim.
      </span>
    </footer>
  </body>
</html>
